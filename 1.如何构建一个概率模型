假设我们现在得到了一个任务，我们要怎么一步一步用代码把它搭建起来呢？这里以分类任务为例

首先，我们需要设计一套神经网络，对输入进行特征提取，然后根据提取的特征，构建一个分类器；

常见的分类问题，要么是二分类，要么是多分类问题；对于二分类问题，我们一般会使用逻辑回归分类器(请认真了解这个最基本的分类器，以及它和sigmoid之间联系)；
对于多分类问题，我们一般使用softmax分类器；通过选定分类器，我们就能够得到每个样本的分类概率

那么，有了概率之后，我们是如果去优化这个分类器的呢？
这里，我们需要了解极大似然估计，极大似然估计的思想是，对于一个未知的分布，我们可能仅仅知道其形式，但是具体的参数取值，我们并不清楚；因为我们有理由相信，
我们拥有的样本存在，说明这些样本出现的概率一定会相对更大，所以，我们想办法估计那个分布的参数值，让这些样本所对应的概率最大化，这就是极大似然估计！

所以，我们需要用之前确定好的分类器，对所有样本求解概率函数，然后将这些样本概率函数连乘起来，得到最终的似然函数！这里大家应该就能理解什么叫做似然函数了，
就是所有样本的概率值连乘形式。连乘的形式不好求解，所以我们一般将其转换为对数似然函数，也就是将似然函数取一个log，这样连乘就变成连加了；事实上，在训练
过程中，我们一般使用的是负对数似然函数，因为我们可以用优化器进行最小化优化！

我们得到了负对数似然函数之后，我们需要对这个值进行优化，让它的值越小越好，这个时候，我们就可以直接使用一些现成的优化器进行优化了！


这里，我想强调的是，我们需要了解分类器是怎么构造的，常见的分类器的形式是什么？以及利用极大似然估计来构造似然函数，有了这些，我们才可以进行训练和优化！
